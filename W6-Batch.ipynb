{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85da89b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0f276b9",
   "metadata": {},
   "source": [
    "# W6 - Batch\n",
    "\n",
    "This notebook contains personal notes and Python, Numpy and Latex of exercises from the \"AI by Hand ✍️ Workbook\" by Prof. Tom Yeh.\n",
    "\n",
    "\n",
    "Reference: [AI by Hand - W6: Batch](https://www.byhand.ai/t/workbook)\n",
    "\n",
    "**Contents:**\n",
    "- Multiple input vectos \n",
    "- Numpy and the transponsed input matrix\n",
    "- Batch \n",
    "    - Sum\n",
    "    - Mean\n",
    "    - Add \n",
    "    - Substract \n",
    "    - Multiply\n",
    "    - Batch Center at Zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e1c138",
   "metadata": {},
   "source": [
    "## Multiple input vectors\n",
    "\n",
    "X is the input matrix\n",
    "\n",
    "$X = (x1, x2)$\n",
    "\n",
    "$y = w*X+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cbb24f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 4]]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def ReLU(x):\n",
    "    # DRY\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "\n",
    "X = np.matrix([[1, 3],[2 ,0]])\n",
    "W = np.matrix([2,1])\n",
    "b = 0\n",
    "result = ReLU(np.dot(W,np.transpose(X))+b)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188c120",
   "metadata": {},
   "source": [
    "## Numpy and the transponsed input matrix\n",
    "\n",
    "Can NumPy automatically handle matrix dimensions for dot products, or do we always need to explicitly transpose the input matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b227b9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,2) and (3,2) not aligned: 2 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m W = np.matrix([\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m])\n\u001b[32m      6\u001b[39m b = -\u001b[32m1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m result = ReLU(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m+b)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[31mValueError\u001b[39m: shapes (1,2) and (3,2) not aligned: 2 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Exercise 3\n",
    "\n",
    "\n",
    "X = np.matrix([[1, 2],[2 ,1], [1,1]])\n",
    "W = np.matrix([1,2])\n",
    "b = -1\n",
    "result = ReLU(np.dot(W,X)+b)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a45d8f8",
   "metadata": {},
   "source": [
    "No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0ad28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 3 2]]\n"
     ]
    }
   ],
   "source": [
    "result = ReLU(np.dot(W,np.transpose(X))+b)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277dc43",
   "metadata": {},
   "source": [
    "## Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4626705",
   "metadata": {},
   "source": [
    "### Batch Sum \n",
    "\n",
    "Transforms the $Y$ matrix with $\\mathbf{y}$ vectors (one per neuron) and length equal to the number of inputs $N$ into one output per neuron.\n",
    "\n",
    "We have the outputs $y_{j,i}$, where $j$ is the neuron index and $i$ is the input index (e.g., user).\n",
    "\n",
    "$Y =  \\mathrm{ReLU}(W X^T + b) $\n",
    "\n",
    "**Batch Sum in LaTeX:**\n",
    "$$\n",
    "S_j = \\sum_{i=1}^N y_{j,i}\n",
    "$$\n",
    "where $S_j$ is the batch sum for neuron $j$.\n",
    "\n",
    "- Transforming the bias array into a column vector and broadcasting it\n",
    "- Why is this useful? Example: We could have 40 inputs and just 3 outputs. Some examples:\n",
    "    - It is useful for Mini-Batch Gradient Descent for computing the total loss\n",
    "    - For image classification. If you have one neuron per class, summing will give total activation per class.\n",
    "    - For recommendations. 100 users and 10 neurons, one neuron per product, doing batch sum will give the most activated products for a group of users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "81a0952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre Activation\n",
      "[[ 4  4  4  0]\n",
      " [ 2  0  2  4]\n",
      " [ 1  3  1 -5]]\n",
      "Post Activation\n",
      "[[4 4 4 0]\n",
      " [2 0 2 4]\n",
      " [1 3 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 11\n",
    "X = np.matrix([[3, 1],[2 ,2], [3,1], [2,-2]])\n",
    "W = np.matrix([[1,1],[1,-1],[0,2]])\n",
    "b = np.array([0,0,-1])\n",
    "\n",
    "pre_activation = np.dot(W,X.T) + b[:, np.newaxis]\n",
    "print(\"Pre Activation\")\n",
    "\n",
    "print(pre_activation)\n",
    "\n",
    "post_activation = ReLU(pre_activation) # size 3x4\n",
    "\n",
    "print(\"Post Activation\")\n",
    "\n",
    "print(post_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "beae8849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0]\n",
      " [ 0]\n",
      " [-1]]\n",
      "[[ 0  0 -1]]\n"
     ]
    }
   ],
   "source": [
    "# New concept here. Reshaping the array into a column vector. This can be broadcasted in order to add it to all columns. Essentially expending its dimensions. \n",
    "print(b[:, np.newaxis])\n",
    "print(b[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "998d2039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n",
      "[[12.  8.  5.]]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 11 + Batch Sum\n",
    "\n",
    "# Batch Sum\n",
    "ones = np.ones(4) # size 1X4\n",
    "print(ones)\n",
    "result = np.dot(post_activation,ones.T)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ef81e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[12],\n",
       "        [ 8],\n",
       "        [ 5]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch sum the numpy way\n",
    "post_activation.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f0ce7",
   "metadata": {},
   "source": [
    "### Batch Mean\n",
    "$\\bar{S}_j = \\frac{1}{N} \\sum_{i=1}^N y_{j,i}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "51d35398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[3.  ],\n",
       "        [2.  ],\n",
       "        [1.25]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_activation.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02728b88",
   "metadata": {},
   "source": [
    "### Batch Add\n",
    "$S_j = \\sum_{i=1}^N (y_{j,i} + v_i) $\n",
    "\n",
    "\n",
    "Where: \n",
    "- v is a vector size number of neurons\n",
    "- N is number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "90ebcb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 4 4 0]\n",
      " [2 0 2 4]\n",
      " [1 3 1 0]]\n",
      "[[2]\n",
      " [1]\n",
      " [2]]\n",
      "Result\n",
      "[[6 6 6 2]\n",
      " [3 1 3 5]\n",
      " [3 5 3 2]]\n"
     ]
    }
   ],
   "source": [
    "add_vector = np.array([2,1,2])\n",
    "\n",
    "add_vector= add_vector[:, np.newaxis]\n",
    "print(post_activation)\n",
    "print(add_vector)\n",
    "print(\"Result\")\n",
    "print(post_activation + add_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d93e73",
   "metadata": {},
   "source": [
    "### Batch Substract\n",
    "$S_j = \\sum_{i=1}^N (y_{j,i} - v_i) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c0d5f30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 4 4 0]\n",
      " [2 0 2 4]\n",
      " [1 3 1 0]]\n",
      "[[2]\n",
      " [1]\n",
      " [2]]\n",
      "Result\n",
      "[[ 2  2  2 -2]\n",
      " [ 1 -1  1  3]\n",
      " [-1  1 -1 -2]]\n"
     ]
    }
   ],
   "source": [
    "add_vector = np.array([2,1,2])\n",
    "\n",
    "add_vector= add_vector[:, np.newaxis]\n",
    "print(post_activation)\n",
    "print(add_vector)\n",
    "print(\"Result\")\n",
    "print(post_activation - add_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d108356a",
   "metadata": {},
   "source": [
    "###  Batch Center at Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0f3dabf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 4 4 0]\n",
      " [2 0 2 4]\n",
      " [1 3 1 0]]\n",
      "Mean\n",
      "[[3.  ]\n",
      " [2.  ]\n",
      " [1.25]]\n",
      "Result\n",
      "[[ 1.    1.    1.   -3.  ]\n",
      " [ 0.   -2.    0.    2.  ]\n",
      " [-0.25  1.75 -0.25 -1.25]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(post_activation)\n",
    "print(\"Mean\")\n",
    "print(np.mean(post_activation, axis=1))\n",
    "\n",
    "print(\"Result\")\n",
    "print(post_activation - np.mean(post_activation, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aibyhand",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
